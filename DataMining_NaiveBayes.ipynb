{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7QWhZB6DhI2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn import metrics\n",
        "from random import randrange\n",
        "from math import sqrt\n",
        "from math import exp\n",
        "from math import pi\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/dm/Project2/project2_dataset2.txt\"\n",
        "df = pd.read_csv(file_path,sep='\\t',header=None)\n",
        "for i in range(df.shape[1]):\n",
        "  if df[i].dtype == object and isinstance(df.iloc[0][i], str):\n",
        "   df[i] = pd.factorize(df.iloc[:,i])[0]\n",
        "\n",
        "X = df.iloc[:,:-1]\n",
        "Y = df.iloc[:,-1]\n",
        "print(X)\n",
        "print(Y)\n",
        "\n",
        "#Preparing the dataset for the algorithm\n",
        "data = df.values.tolist()\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Separate By Class"
      ],
      "metadata": {
        "id": "2g8cgrlUEXzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def separate_by_class(dataset):\n",
        "    separated = dict()\n",
        "    for i in range(len(dataset)):\n",
        "        row = dataset[i]\n",
        "        class_value = row[-1]\n",
        "        if class_value not in separated:\n",
        "            separated[class_value] = list()\n",
        "        separated[class_value].append(row)\n",
        "    return separated"
      ],
      "metadata": {
        "id": "W-q6fLZWEPv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Summarize the dataset"
      ],
      "metadata": {
        "id": "qZGEOSvzlN9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean(dataset):\n",
        "  mean_values = np.mean(dataset,axis=0)\n",
        "  return mean_values\n",
        "\n",
        "def stddev(dataset):\n",
        "  std_values = np.std(dataset, axis=0)\n",
        "  return std_values\n",
        "\n",
        "def summarize_dataset(dataset):\n",
        "\tsummaries = [(mean(column), stddev(column), len(column)) for column in zip(*dataset)]\n",
        "\tdel(summaries[-1])\n",
        "\treturn summaries"
      ],
      "metadata": {
        "id": "tEopwnrek1Eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Summarize data by class"
      ],
      "metadata": {
        "id": "mCweUKl-mvDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset by class then calculate statistics for each row\n",
        "def summarize_by_class(dataset):\n",
        "\tseparated = separate_by_class(dataset)\n",
        "\tsummaries = dict()\n",
        "\tfor class_value, rows in separated.items():\n",
        "\t\tsummaries[class_value] = summarize_dataset(rows)\n",
        "\treturn summaries\n",
        "\n",
        "summary = summarize_by_class(data)\n",
        "for label in summary:\n",
        "\tprint(label)\n",
        "\tfor row in summary[label]:\n",
        "\t\tprint(row)"
      ],
      "metadata": {
        "id": "Mht2Atqrmrla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step* 4: Gaussian Probability Density Function"
      ],
      "metadata": {
        "id": "1_2_bLHrraxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def calculate_probability(x, mean, stdev):\n",
        "\texponent = math.exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
        "\treturn (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent"
      ],
      "metadata": {
        "id": "kVSbK_uUrdnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Class Proabilities"
      ],
      "metadata": {
        "id": "4oWX9qzi6unE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_probability(x, mean, stdev):\n",
        "\texponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
        "\treturn (1 / (sqrt(2 * pi) * stdev)) * exponent\n",
        "\n",
        "def calculate_class_probabilities(summaries, row):\n",
        "\ttotal_rows = sum([summaries[label][0][2] for label in summaries])\n",
        "\tprobabilities = dict()\n",
        "\tfor class_value, class_summaries in summaries.items():\n",
        "\t\tprobabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
        "\t\tfor i in range(len(class_summaries)):\n",
        "\t\t\tmean, stdev, count = class_summaries[i]\n",
        "\t\t\tprobabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n",
        "\treturn probabilities"
      ],
      "metadata": {
        "id": "P_-GsNps6uQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Predict"
      ],
      "metadata": {
        "id": "WO_XLoX37DfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(summaries, row):\n",
        "\tprobabilities = calculate_class_probabilities(summaries, row)\n",
        "\tbest_label, best_prob = None, -1\n",
        "\tfor class_value, probability in probabilities.items():\n",
        "\t\tif best_label is None or probability > best_prob:\n",
        "\t\t\tbest_prob = probability\n",
        "\t\t\tbest_label = class_value\n",
        "\treturn best_label\n",
        "\n",
        "# Naive Bayes Algorithm\n",
        "def naive_bayes(train, test):\n",
        "\tsummarize = summarize_by_class(train)\n",
        "\tpredictions = list()\n",
        "\tfor row in test:\n",
        "\t\toutput = predict(summarize, row)\n",
        "\t\tpredictions.append(output)\n",
        "\treturn(predictions)"
      ],
      "metadata": {
        "id": "R4FduWiNuLL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7. 10-fold Cross Validation"
      ],
      "metadata": {
        "id": "bi4bs_pSIye9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split a dataset into k folds\n",
        "def cross_validation_split(dataset, n_folds):\n",
        "    dataset_split = list()\n",
        "    dataset_copy = list(dataset)\n",
        "    fold_size = int(len(dataset) / n_folds)\n",
        "    for _ in range(n_folds):\n",
        "        fold = list()\n",
        "        while len(fold) < fold_size:\n",
        "\n",
        "            index = randrange(len(dataset_copy))\n",
        "            fold.append(dataset_copy.pop(index))\n",
        "    dataset_split.append(fold)\n",
        "    return dataset_split\n",
        "\n",
        "\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
        "    folds = cross_validation_split(dataset, n_folds)\n",
        "    actual = []\n",
        "    predicted = []\n",
        "    for fold in folds:\n",
        "        train_set = list(folds)\n",
        "        train_set.remove(fold)\n",
        "        train_set = sum(train_set, [])\n",
        "        test_set = list()\n",
        "        for row in fold:\n",
        "            row_copy = list(row)\n",
        "            test_set.append(row_copy)\n",
        "            row_copy[-1] = None\n",
        "        predicted = algorithm(train_set, test_set, *args)\n",
        "        actual = [row[-1] for row in fold]\n",
        "    return actual, predicted"
      ],
      "metadata": {
        "id": "gtJRMmMSIt8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation Metrics - Accuracy, Precision, Recall and F-1 measure"
      ],
      "metadata": {
        "id": "o4o6U7JOJIKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Naive Bayes on project1_dataset1\n",
        "n_folds = 10\n",
        "actual, predicted = evaluate_algorithm(df, naive_bayes, n_folds)\n",
        "\n",
        "print (actual, predicted)\n",
        "\n",
        "accuracy = metrics.accuracy_score(actual, predicted)\n",
        "precision = metrics.precision_score(actual, predicted)\n",
        "recall = metrics.recall_score(actual, predicted)\n",
        "f1_measure = metrics.f1_score(actual, predicted)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Precision: \", precision)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"F1-measure: \", f1_measure)\n"
      ],
      "metadata": {
        "id": "tkOL2Uy094KT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}